{
  "version": 1,
  "nodes": [
    {
      "id": 1,
      "name": "Canvas",
      "type": "graphics.canvas",
      "x": 50,
      "y": 50,
      "values": {
        "width": 604
      }
    },
    {
      "id": 2,
      "name": "Background Color",
      "type": "graphics.backgroundColor",
      "x": 50,
      "y": 100
    },
    {
      "id": 3,
      "name": "Sequence",
      "type": "core.sequence",
      "x": 50,
      "y": 150
    },
    {
      "id": 7,
      "name": "Custom",
      "type": "project.custom",
      "x": 315,
      "y": 297,
      "values": {
        "color": [
          71,
          255,
          60,
          1
        ]
      }
    },
    {
      "id": 8,
      "name": "Load Image",
      "type": "image.loadImage",
      "x": 342,
      "y": 116,
      "values": {
        "file": "assets/wutang.png"
      }
    },
    {
      "id": 9,
      "name": "Draw Image",
      "type": "image.drawImage",
      "x": 55,
      "y": 295
    }
  ],
  "connections": [
    {
      "outNode": 1,
      "outPort": "out",
      "inNode": 2,
      "inPort": "in"
    },
    {
      "outNode": 2,
      "outPort": "out",
      "inNode": 3,
      "inPort": "in"
    },
    {
      "outNode": 3,
      "outPort": "out1",
      "inNode": 9,
      "inPort": "in"
    },
    {
      "outNode": 3,
      "outPort": "out2",
      "inNode": 7,
      "inPort": "in"
    },
    {
      "outNode": 8,
      "outPort": "image",
      "inNode": 7,
      "inPort": "image"
    },
    {
      "outNode": 8,
      "outPort": "image",
      "inNode": 9,
      "inPort": "image"
    }
  ],
  "types": [
    {
      "name": "Custom",
      "type": "project.custom",
      "source": "// face api node.\nconst ml5 = require('ml5');\nconst triggerIn = node.triggerIn('in');\nconst imageIn = node.imageIn('image');\nconst colorIn = node.colorIn('color', [150, 50, 150, 1]);\nlet faceapi;\nlet detections;\nlet options = {\n\twithLandmarks: true,\n    withDescriptors: false,\n }\n\nnode.onStart = () => {\n  faceapi = ml5.faceApi(options, modelReady)\n}\n\nfunction gotResults(err, result) {\n    if (err) {\n        console.log(err)\n        return\n    }\n    detections = result;\n  //console.log(detections)\n}\n\nfunction drawBox(ctx, detection){\n    const alignedRect = detection.alignedRect;\n    const {_x, _y, _width, _height} = alignedRect._box;\n    ctx.save();\n  \tctx.strokeStyle = g.rgba(...colorIn.value);\n  \tctx.strokeRect(_x, _y, _width, _height);\n  \tctx.restore();\n}\n\nfunction drawLandmarks(ctx, detection){\n        const mouth = detection.parts.mouth; \n        const nose = detection.parts.nose;\n        const leftEye = detection.parts.leftEye;\n        const rightEye = detection.parts.rightEye;\n        const rightEyeBrow = detection.parts.rightEyeBrow;\n        const leftEyeBrow = detection.parts.leftEyeBrow;\n        drawPart(ctx, mouth, true);\n        drawPart(ctx, nose, false);\n        drawPart(ctx, leftEye, true);\n        drawPart(ctx, leftEyeBrow, false);\n        drawPart(ctx, rightEye, true);\n        drawPart(ctx, rightEyeBrow, false);\n}\n\nfunction drawPart(ctx, feature, closed){\n  ctx.strokeStyle = g.rgba(...colorIn.value);\n  ctx.beginPath();\n  for(let i = 0; i < feature.length; i++){\n     const x = feature[i]._x\n     const y = feature[i]._y\n     ctx.lineTo(x, y);\n  }\n  ctx.stroke();  \n}\n        \nfunction modelReady() {\n  console.log(\"Model Loaded!\");\n  faceapi.detect(imageIn.value, gotResults)\n}\n        \ntriggerIn.onTrigger = (props) => {\n   const { canvas, ctx } = props;\n      if (detections) {\n        for(let i = 0; i < detections.length;i++){\n        drawBox(ctx, detections[i])\n        drawLandmarks(ctx, detections[i])\n        }\n    }\n};\n\nimageIn.onChange = () => {\n   faceapi.detect(imageIn.value, gotResults)\n}\n\ncolorIn.onChange = () => {\n   faceapi.detect(imageIn.value, gotResults)\n}\n\n",
      "description": "face api node."
    }
  ]
}